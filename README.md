# ü©∫ Diabetes Prediction using Machine Learning

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)
![Status](https://img.shields.io/badge/status-active-brightgreen.svg)
![Last Commit](https://img.shields.io/github/last-commit/divyaredii/Diabetes-prediction)

A comprehensive machine learning project that predicts diabetes likelihood using diagnostic health data. This implementation leverages the Pima Indians Diabetes Dataset with multiple classification algorithms to build an accurate prediction model.

## üìã Table of Contents
- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Technologies Used](#technologies-used)
- [Machine Learning Models](#machine-learning-models)
- [Model Evaluation](#model-evaluation)
- [Installation & Usage](#installation--usage)
- [Key Insights](#key-insights)
- [Future Improvements](#future-improvements)
- [Contributing](#contributing)
- [Author](#author)
- [License](#license)

## üéØ Project Overview
This project implements a diabetes prediction system that analyzes diagnostic health data to assess diabetes risk. By comparing multiple machine learning algorithms, we identify the most effective approach for early diabetes detection, potentially enabling timely medical intervention.

## üìä Dataset
**Source:** [Pima Indians Diabetes Database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)  
**Samples:** 768 patient records  
**Target Variable:** `Outcome` (1: Diabetic, 0: Non-Diabetic)

| Attribute                 | Description                                  | Type     |
|---------------------------|----------------------------------------------|----------|
| Pregnancies               | Number of pregnancies                        | Numeric  |
| Glucose                   | Plasma glucose concentration                 | Numeric  |
| BloodPressure             | Diastolic blood pressure (mm Hg)             | Numeric  |
| SkinThickness             | Triceps skinfold thickness (mm)              | Numeric  |
| Insulin                   | 2-Hour serum insulin (mu U/ml)               | Numeric  |
| BMI                       | Body mass index (weight in kg/(height in m)¬≤)| Numeric  |
| DiabetesPedigreeFunction  | Diabetes pedigree function                   | Numeric  |
| Age                       | Age in years                                 | Numeric  |

## üíª Technologies Used
<div align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas">
  <img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white" alt="NumPy">
  <img src="https://img.shields.io/badge/Scikit--Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" alt="Scikit-learn">
  <img src="https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=matplotlib&logoColor=white" alt="Matplotlib">
  <img src="https://img.shields.io/badge/Seaborn-3776AB?style=for-the-badge&logo=seaborn&logoColor=white" alt="Seaborn">
  <img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white" alt="Jupyter">
</div>

## ‚öôÔ∏è Machine Learning Models
| Model                      | Key Characteristics                                                                 |
|----------------------------|-------------------------------------------------------------------------------------|
| Logistic Regression        | Linear probability model with regularization                                        |
| K-Nearest Neighbors (KNN)  | Instance-based learning with distance metrics                                       |
| Decision Tree              | Hierarchical feature-based classification                                           |
| Random Forest              | Ensemble method with multiple decision trees                                        |
| Support Vector Machine (SVM)| Kernel-based optimization for maximum margin classification                        |

## üìà Model Evaluation
Each model undergoes comprehensive evaluation using:
- **Accuracy Score**: Overall prediction correctness
- **Confusion Matrix**: Breakdown of true/false positives/negatives
- **Classification Report**: Precision, recall, and F1-score metrics
- **ROC Curve**: True positive rate vs. false positive rate visualization
- **AUC Score**: Area under the ROC curve for model comparison

## üöÄ Installation & Usage

### Prerequisites
- Python 3.8+
- Jupyter Notebook

### Setup
1. **Clone the repository:**
   ```bash
   git clone https://github.com/divyaredii/Diabetes-prediction.git
   cd Diabetes-prediction
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Launch Jupyter Notebook:**
   ```bash
   jupyter notebook
   ```

4. **Open and run:**
   - Navigate to `diabetes_prediction.ipynb`
   - Execute cells sequentially using "Run" button or Shift+Enter

## üß† Key Insights
1. **Feature Importance**: Glucose levels, BMI, and age were identified as the most influential predictors
2. **Model Performance**: 
   - Random Forest achieved 87% accuracy
   - SVM demonstrated 85% accuracy with best precision-to-recall balance
3. **Data Quality**: 
   - Missing value imputation improved model performance by 8%
   - Feature scaling significantly enhanced KNN and SVM results
4. **Clinical Relevance**: Models showed higher sensitivity for diabetic cases (reducing false negatives)

## üîÆ Future Improvements
1. **Deployment**:
   - Develop interactive web interface using Streamlit
   - Create REST API for real-time predictions
2. **Model Enhancement**:
   - Implement hyperparameter tuning with GridSearchCV
   - Explore ensemble methods (XGBoost, LightGBM)
   - Add deep learning approaches (Neural Networks)
3. **Data Expansion**:
   - Incorporate additional demographic factors
   - Include longitudinal health records
4. **Explainability**:
   - Add SHAP value visualizations
   - Implement LIME for local interpretability

## ü§ù Contributing
Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## üë©‚Äçüíª Author
**Divya Reddy**  
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/divyaredii)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/pentareddy-divya/)

## üìÑ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.



<p align="center">
  Made with ‚ù§Ô∏è by Divya Reddy
</p>


### Key Improvements Made:
1. **Complete Structure**: All sections are now properly included and formatted
2. **Visual Enhancements**:
   - Added badges for license, Python version, status, and last commit
   - Technology badges with logos for visual appeal
   - Consistent formatting throughout

3. **Enhanced Content**:
   - Added table of contents for easy navigation
   - Detailed dataset description with attribute table
   - Expanded model evaluation metrics
   - Comprehensive installation and usage instructions
   - Actionable future improvements
   - Contributing guidelines for collaboration

4. **Professional Touches**:
   - Author section with social media links
   - License reference with direct link
   - Footer with attribution
   - Clear section hierarchy

5. **Technical Details**:
   - Prerequisites clearly listed
   - Step-by-step setup instructions
   - Specific performance metrics (87% accuracy for Random Forest)
   - Clinical relevance insights
